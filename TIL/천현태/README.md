## 싸라벨

- 나이가 많으신 어르신들의 구직 및 복지를 위한 플랫폼

---

## 2.27

#### 주 내용

- 아이디어 기획 회의 - 1차
- 개인 별 아이디어 찾아본 후 의견 나눔
  - 냉장고의 재료로 만들 수 있는 음식 추천 (냉.부)
  - 취준생의 기술 스택을 바탕으로 관심 뉴스 추천
  - 해외 여행 추천
- 위 3개에 대해 피드백
  - 데이터를 어떤 기준으로 input을 어떻게 줄건지 ?
  - 특히 뉴스의 경우 실시간성을 어떻게 해결할지.
  - 데이터 긁어와서 전처리를 해주어야 한다.
  - 파이프라인을 그려보기

#### 배운 점

- 레프가 많아서 추천이 좋아보이지만, 차별성을 두기가 어려웠습니다.
- 기존의 데이터가 아닌 새로운 데이터 및 페르소나를 그려보는 것 또한 중요하다고 느꼈습니다. 기존 데이터를 사용한다면, 존재하는 컬럼에 맞춰서 할 수 밖에 없기 때문!!
- 주제 및 기능 선정시 -> 예외처리, 추천 알고리즘에 대해 많은 공부가 필요할 것 같습니다.
- 유사도 판단을 위해 INPUT , OUTPUT 을 모두 고려해주는 것이 기획의 시작이라고 생각합니다.
  - 정작 아이디어를 내고 보니 어떤 데이터를 주고 어떤 데이터를 받을지를 생각하지 않았었습니다.
  - 결국, OUTPUT을 따져보니 첫 생각과는 많이 다르다는 것을 알 수 있었습니다.
- 첫 날부터 많은 것을 알게 되었다.

---

## 02.28

#### 주 내용

- 개인별 주제 더 생각해와서 발표
  - 소비 습관 기반 상품 추천
  - 카페 API 활용 추천
  - 특허 기반 관심 분야 회사 추천
  - 도서 추천
  - 취약 계층 정책 / 구인 / 복지 추천
  - - 어제 2가지
- 마찬가지로 컨설턴트님께 피드백
  - 데이터는 만들 수 있으므로, **아웃풋**을 생각해보자!!
  - 즉, 내가 잘 알거나, 학습이 되어있어야 한다.
    - 따라서, 금융 상품의 경우 전문가 수준이 되어야 신뢰성 있는 추천이 된다.
  - 또한, 인풋을 주었을 때 받는 아웃풋으로 어떤 걸 할 수 있는지를 생각해야된다.
  - 어떤 알고리즘을 사용할건지 생각해봐라. -> 가짜 데이터 만들기

#### 배운 점

- 블로그 등을 크롤링 한 후 -> 전처리 -> 스키마를 짜는 FLOW를 알 수 잇었습니다.
- 어떤 값을 input으로 사용할지 잘 정하고, 해당 output을 기준으로 CB, CF 알고리즘을 사용하면 될 것 같습니다.
- 아직 빅데이터 도메인에 대해 지식이 많이 부족하여 학습을 열심히 할 필요가 있을 것 같습니다. 특히 어떤 모델을 선택할지, 피드백을 선택할지를 선택하기 위해 기획을 열심히 할 필요가 있다는 것을 알 수 있었습니다.
- 기획을 확실히 하여야 나중에 우리가 편하고 완성도도 높다 !!

---

## 03.01

- 삼일절

---

## 03.02

- 코딩테스트로 인한 공가

---

## 03.03

#### 주 내용

- 현업자 멘토링 위한 질문 정리
- 데이터 수집
  - 복지와 구인 공고
- 오픈 API 요청 거절 및 새로운 데이터 찾기
- 복지와 구인 중 어느 것에 비중을 둘지 토의를 진행하며 전체적인 큰 틀 찾아가는 중

#### 깨달은 점

- 데이터를 수집하는 것을 많은 레프를 통해 진행하며 우리의 입맛에 맞게 수집 및 가공이 필요하다는 것을 다시 확인했습니다.
- 현업자 분께 질문할 리스트를 정리하며 우리가 필요한 것, 궁금한 것을 정리하는 과정에서
  - 아직 도메인 지식이 많이 부족해 질 나쁜 질문밖에 생각나지 않았습니다.
  - 추가적인 학습을 통해 잘 정리하여 좋은 결과를 얻어야 될 것 같습니다.

---

## 03.06

#### 주 내용

- 오전, 오후 모두 회의 진행
- 유저 FLOW를 그리며 전체 기능들에 대한 각자의 생각을 MERGE 하는 과정을 가졌음
- 추천 알고리즘에 어떤 COLUMN들을 사용할지 고민해봄
- 레프할 사이트들을 정리하며 CBF 컬럼 정리
- 복지에 알고리즘을 적용할지 말지 고민
- 피그마 진행

#### 깨달은 점

- 프로젝트의 내용 및 방향성을 팀 구성원들 모두 통일시키는 과정이 꼭 필요하다고 생각하였습니다.
- 추천 알고리즘을 공부하며 어떤 COLUMN 들이 유의미하고 어떻게 가중치를 줘야되는지 각자 의견을 나누며 발전하고 있습니다.
- 피그마를 잘 다져놓으면서 진행하니 서로 이해하는거도 빠르고 대화의 진행이 매끄럽다는 것을 느꼈습니다.
- 프로젝트의 볼륨을 우리의 목적에 맞게 잘 설정하는 것이 중요하다!!

---

## 03.07

#### 주 내용

- 수집한 복지 및 고용 데이터의 컬럼을 확인 및 알고리즘에 대해 회의
- 레퍼 코드를 참고하며 어떤 식으로 알고리즘이 동작하는지, 어떤 컬럼이 필요한지를 분석하며 일복 프로젝트에선 어떤 식으로 사용할지 토의
- 피그마 계속 진행하며 상세 페이지의 기능 확정

#### 깨달은 점

- 아직 많이 더딘 것 같지만, ERD와 기능을 확실히 정한다면 속도가 날 것 같습니다.
- 개인이 진도를 나가기 위해선 팀적으로 필요한 부분들을 가능한 빨리, 신중하게 결정하는 것이 중요한 것 같습니다.

---

## 03.08

#### 주 내용

- 레프 코드를 어느정도 사용할지 토의하며, 참고용으로만 사용하고 우리만의 프로젝트를 진행하기로 함
- 기존 복지 레프기 때문에 이를 참고로 일자리 알고리즘을 어떤 방향으로 가져가야 할 지 토의하였음
- 일자리가 중점인 프로젝트이기 때문에 불필요한 부분의 기능들은 옵션으로 남겨두기
- 기능 명서세를 2인 1조로 작성하며 필수불가결한 데이터와 옵션 데이터를 나눠주며 페이지 별로 기능 확정

#### 깨달은 점

- 아직 서류 작성이 많이 되어있지 않아 회의록을 보고 나눴던 기능들에 대해 얘기하니 다시 처음으로 돌아가는 부분들이 존재
- 오늘 내일안에 서류를 작성하며 전체적인 흐름, 사용 기능, API, ERD에 대해 전체적으로 생각을 합칠 필요가 있었고 이번 주 내로 개발 시작 예정
- 정말 부지런해져야 겠다고 생각합니다.
  - 회의만으로도 알고리즘, 자소서 등 개인 공부할 시간이 부족하다고 느끼는 중..
  - 잠을 줄이고 계획을 짜서 효율적으로 시간을 써야겠다고 느꼈습니다.
- 프로젝트 시작하기 전 확실히 기능 및 프레임워크에 대해 더 학습할 필요가 있다고 생각했습니다.

---

## 03.09

#### 주 내용

- CF, CBF 알고리즘에 대해 회의
  - 어떤 식으로 어디에 적용을 할 것인가
  - User Based 사용 또는 Item Based 사용
- ERD 구성하기

#### 깨달은 점

- 병원 내원으로 디스코드로 참여했는데 다같이 들어와줘서 오전 회의 내용을 알 수 있었습니다.
- 전체 흐름은 다같은 방향성으로 생각해야 되기 때문에 꼭 필요한 부분이라고 생각했는데 너무 감사합니다 팀원분들 ㅠ
- 기능 정리 후 ERD 작성을 하며 피그마와 ERD 작성의 중요성을 다시 깨달았습니다.
  - 초석이 잘 깔려있다면 이후에 이슈가 발생하더라도 해결하는 것이 더 수월하다는 것을 이전 프로젝트에서도 뼈저리게 느꼈습니다!
- FRONT라도 DB에 관련된 것들을 알고 BACKEND 회의 등을 같이 참여하며 팀원의 역할, 할 일에 대해 이해하는 것이 팀을 함께 끌고 나가는 것에 대해 많이 도움이 되는 것 같습니다.
  - 특히, 얘기를 나누며 의견 조율이 필요할 때 건설적인 대화를 나눌 수 있는 것 같습니다.

---

## 3.10

#### 주 내용

- ERD 설계 및 현업자 멘토링

#### 깨달은 점

- 생각을 조금만 바꾸면 더 이해하기 쉽다는 것을 느꼈습니다.
  - cf 를 돌리며 어떤 컬럼을 대상으로 해야될지 어려웠는데
  - 별점이라는 예시를 듣고 많은 아이디어를 구상할 수 있었습니다.

---

## 3. 13

#### 주 내용

- 덤프 데이터 생성 및 erd 설계 완료
- 개발 단계 진입

#### 깨달은 점

- erd 양이 많이 않았지만 팀원들과 어떤 컬럼을 어떻게 사용할지 정하는 것이 조금 오래 걸렸습니다.
- 기능을 퀄리티 있게 구현하기 위해선 필요한 부분이라 생각합니다.

---

## 3.14

#### 주 내용

- 개인 일정으로 인해 휴식..

---

## 3.15

#### 주 내용

- 직종 코드 파싱
- 장고 셋업
- 리액트 페이지 구현

#### 깨달은 점

- 이제 개발에 박차를 가해야 된다!!
- API 설계 및 알고리즘 구현 필요

---

## 3.16

- 예비군 훈련

---

## 3.17, 3.20, 3.21

- 추천 알고리즘 추가 공부
- 라이브러리 이용하여 벡터화 시키기

---


## 3.22

#### 주 내용

- cbf 알고리즘 위한 벡터행렬 만들기
- 현업 선배님 멘토링



--- 

## 03. 23, 03.24

#### 주 내용

- 채용공고 벡터화 시키기
	- 직종 대분류 - 중분류 - 소분류 - 지역 대분류 - 소분류 - 학력 - 고용 조건 - 최소 학력
	- npy 파일로 내보내기
		- csv 파일로 내보낼시 문자열로 저장되어 이후 cos similarity 사용시 int 변환 필요

- 특성 나열한 행렬을 그대로 저장 후, 공고 클릭시 해당 공고와의 유사도 계산 로직
	- 현재 4천개 정도여서 금방 계산

```python

def similar_job(wanted_job):
    all_job_List = load_job_matrix()
    job_job_similar = []
    for i in range(1, len(all_job_List)):
        if i != wanted_job:
            job_job_similar.append((cos_sim(all_job_List[wanted_job], all_job_List[i]), i))
    job_job_similar.sort(key=lambda x:x[0], reverse=True)
    similar_job_code = [i[1] for i in job_job_similar[:5]]
    print(similar_job_code)
    return job_job_similar[:5]
```


- 이후 데이터가 많아질 것을 대비하여, sklearn cos_similarity 이용하여 해당 공고에 대한 유사도 matrix 자체를 저장해두기



```python

# 직업 별 유사도 행렬 불러와서 상위 5개 뽑아주기

def job_sort():

    jobMatrix = np.load('jobMatrix.npy')

    # 유사도 비교하여 저장

    calc_sim_job = cosine_similarity(jobMatrix, jobMatrix)

    # 유사도가 큰 순으로 정렬한 인덱스를 추출하되 자기 자신 제외하기

    sorted_index = np.argsort(calc_sim_job)[:, ::-1]

    sorted_index = sorted_index[:, 1:]

    sim_job = []

    # 현재 인덱스 번호이므로 실제 공고 번호로 변경해준 후 저장

    for i in sorted_index:

        sim_job.append(i[:5])

  

    np.save('sim_job_num', sim_job)

    return sim_job
```


- 공고 - 공고간 유사도 끝!
- 구직자에 대한 행렬의 열 데이터 뽑아내고 유사도 돌리기.
	- 이 때, '내가 본 공고를 본 다른 구직자'를 한정으로 하기 때문에, 실시간성으로 해야된다.


#### 배운 점

- 로직을 어떻게 짜야될지 모를 땐 완전 탐색으로라도 우선 짜기!
- 이후 개선 방향 생각해보자.
- 행렬을 만들 때, 유효한 데이터를 잘 뽑아내서, 유사도를 해야 정확한 결과가 나온다.
- argsort()를 이용하여 인덱스를 뽑아내고, 이를 통해 유사한 공고 번호를 뽑아냈는데, numpy의 경우 1차원 배열밖에 사용할 수 없어서 
	- 인덱스를 참조할 리스트를 꼭 들고 있어야된다!!
- cos_similarity를 사용한 이유
	- jakard의 경우 특성의 종류가 적은 경우 별로 좋지 않았고, 직업 유형에 binary가 아닌 것이 있었기 때문에 사용했습니다.
- numpy -> dot이 아닌 sklearn cos_similarity 사용한 이유
	- 공고 데이터는 자주 바뀌지 않으므로 미리 계산해 놓고 dump를 만들어 놓는 것이 효율적이라고 생각했습니다.


---

## 03.27, 03.28

#### 주 내용

- jobMatrix의 기존 행렬을 변경해줌으로써 유사도에 정확성을 더 부여해줌
- 학력, 경력을 각자의 열이 아닌 포함 관계를 통해 가중치를 더해줬습니다.
	- 학력무관 2~3대졸 4대졸 석사 박사 가 해당 열에 대해서만 1을 주는 것이 아닌
	- 지원 가능한 하위 항목에도 1을 더해주는 것으로 변경
	- 즉 5개 -> 4개의 열로 변경 후,
	- 학력 무관인 경우 1 1 1 1 로 모든 학력에 대해 가중치를 줌

> 학력

```python
# 학력
        a = job.degree_code.degree_id
        if a == 0:
            jobMatrix[job.code][1527:1531] = [1, 1, 1, 1]       # 학력무관 - 1 1 1 1
        elif a == 4:
            jobMatrix[job.code][1527:1531] = [0, 1, 1, 1]       # 대졸 2~3 - 0 1 1 1
        elif a == 5:
            jobMatrix[job.code][1527:1531] = [0, 0, 1, 1]       # 대졸 4   - 0 0 1 1
        elif a == 6:
            jobMatrix[job.code][1527:1531] = [0, 0, 0, 1]       # 석사     - 0 0 0 1
        else:
            jobMatrix[job.code][1527:1531] = [0, 0, 0, 0]       # 박사     - 0 0 0 0
```


> 근무일수

```python
 # 주 근무 일수
        working = job.working_day
        if working == "주6일근무":
            jobMatrix[job.code][1531] = 1
        elif working == "주5일근무":
            jobMatrix[job.code][1532] = 1
        elif "주 5일 미만":
            jobMatrix[job.code][1533] = 1
```



> 경력

```python
# 경력
        car = job.career
        if car == "관계없음":                                   
        # 관계없음    1   1
            jobMatrix[job.code][1535:1537] = [1, 1]
        elif car == "신입":                                     
        #  신입       1   0
            jobMatrix[job.code][1535:1537] = [1, 0]        
        elif car == "경력":                                     
        #  경력       0   1
            jobMatrix[job.code][1535:1537] = [0, 1]
```


- 기존 최대 유사도

	![[assets/Pasted image 20230328162650.png]]

- 변경 후 유사도
	- 변경 후, 최대 유사도와 최소 유사도가 변경된 것을 볼 수 있습니다.
 
![[assets/Pasted image 20230328162805.png]]



- 또한 지역 대분류에 대한 가중치가 빠져있어서 추가해주었습니다.

![[천현태/assets/Pasted image 20230328233503.png]]


#### 배운 점

- matrix를 만들며 모든 열을 생성하지 않았다면, 개선의 여지가 없었을 수도 있다고 생각합니다.
- 최대한 비슷한 항목을 생각했고, 경력 및 지역의 경우 범주형 카테고리이기 때문에 자카드 유사도를 사용하려고 하였지만
	- 학력과 경력유무의 경우 상위 - 하위 관계를 확실히 할 수 있었기 때문에 가중치를 주고 비교하였습니다.
	- 확실히 가중치과 포함관계가 들어가니 더욱 정확한 유사도가 나오는 것을 볼 수 있었습니다.
- 처음 설계의 중요성에 대해 배울 수 있었습니다.
	- 모든 특성에 대해 상세히 고려하지 않으니 중간중간 코드바꾸는 것이 힘들었습니다 ㅠ...

---

## 03.29

- 유저 매트릭스 생성
	- 직업 대분류 - 중분류 - 지역 - 학력
	- 경력과 선호하는 공고의 경우 가중치를 달리하여 직업에  + 해주었습니다.
	- 유저-유저 간 유사도는 관심있는 공고에 가중치를 많이 두기로 하여
		- 선호 공고 -> +3
		- 경력의 경우 -> 1년 미만 1점, 3년 이하 2점, 4~ 부터는 3점을 주었습니다.
- 이후 user-user cos_similarity를 계산하는데
	- 우선, 모든 이웃에 대해서 구해주었습니다.
	- 유사도가 비슷하게 나오는 문제가 발생하였고, 나이를 기록하는데 있어 문제가 있다는 것을 알게 되었습니다.
	- 


- 특성과 데이터 들고와서
	- 특성당 인덱스 매겨주기

```python
all_user = Users.objects.values('user_id','degree_code', 'city_code', 'favorite', 'age','gender')

    # job 코드 변수
    js = JobSubFamily.objects.all()
    jc = JobCategory.objects.all()

    # 지역변수
    city = Cities.objects.all()
    region = Regions.objects.all()

    # 유저경력 변수
    career = Careers.objects.all()
  

    # 직업 중분류 - 행렬 인덱스 매칭
    sub_to_index = {}
    for i in range(len(js)):
        sub_to_index[js[i].code] = i+14
  

    # 지역 - 행렬 인덱스 매칭
    city_to_region = {}
    city_to_index = {}
    region_to_index = {}

    i = 126
    for k in region:

        region_to_index[k.code] = i

        i += 1
    # city - region 매칭
    # city - 행렬 인덱스 매칭
    for j in range(len(city)):

        city_to_region[city[j].code] = city[j].region_code.code

        city_to_index[city[j].code] = j + 144
```

```python
# 우선 전체 유저의 수 구하기

    user_length = all_user.aggregate(Max('user_id'))

    userMatrix = [[0]*379 for _ in range(user_length['user_id__max']+1)]
```
	
 
- 정해진 가중치에 따라 matrix에 기록
```python

 # 유저 정보에 대해 matrix에 기록
    for us in all_user:
        us_num = us['user_id']
        fav = us['favorite']
        us_city = us['city_code']
        deg = us['degree_code']
        us_age = us['age']
        us_gen = us['gender']
  
        # 유저 관심 직종 +3 해주기
        userMatrix[us_num][sub_to_index[fav]] += 3
  
        # 지역 +1 해주기
        userMatrix[us_num][city_to_index[us_city]] += 1
        userMatrix[us_num][region_to_index[city_to_region[us_city]]] += 1

        # 학력 기록해주기
        if deg == 0:
            userMatrix[us_num][373:377] = [0,0,0,0]
        elif deg == 4:
            userMatrix[us_num][373:377] = [0,0,0,1]
        elif deg == 5:
            userMatrix[us_num][373:377] = [0,0,1,1]
        elif deg == 6:
            userMatrix[us_num][373:377] = [0,1,1,1]
        elif deg == 7:
            userMatrix[us_num][373:377] = [1,1,1,1]
            
        # 나이 기록해주기
        userMatrix[us_num][377] = us_age

        # 성별 - 남 1 여 2
        if us_gen == 0:
            userMatrix[us_num][378] = 1
        else:
            userMatrix[us_num][378] = 2
```



#### 배운 점

- 유사도가 전부 0.98이상으로 나와 별 차이가 없었습니다.
	- 이유를 찾으니 age가 50~ 이상으로 숫자로 기록해주었고 각도기반의 cosine 유사도에서는 좋지않게 작용한다는 것을 알게 되었습니다.
	- 따라서, 각 age에 대해 열을 만들어 주거나, 범위를 정하여 0 과 1 로 표현해주는 것이 좋을 것 같습니다
- 성별도 비슷하여, 남 여로 열 구분해주었습니다.


#### 질문

- return 리스트 
- 차원이 많아지는 것이 좋나, 아니면 가중치를 높이는 것이 좋을까?
- 차원이 많아지는 것이 좋다면, 직종당 2개씩?
											- 경력 + 선호
- 유사도가 너무 높다; 
			- 이유 찾음
			- 나이가 많이 때문에 1, 2, 3, 4 정도로 구분해주는 것이 좋을 것 같다.
