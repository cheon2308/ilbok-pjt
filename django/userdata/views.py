from django.shortcuts import render
from django.db.models import Max
from .models import *
import numpy as np
from numpy import dot
from numpy.linalg import norm
import pandas as pd
from scipy import sparse
from sklearn.metrics.pairwise import cosine_similarity
from rest_framework.response import Response
from rest_framework.decorators import api_view
from scipy.sparse.linalg import spsolve
import random
from sklearn.preprocessing import MinMaxScaler
# Create your views here.
from time import time

# ì½”ì‚¬ì¸ ìœ ì‚¬ë„
def cos_sim(A, B):
    return dot(A, B) / (norm(A)*norm(B))

# ìœ ì € íŠ¹ì„± í–‰ë ¬í™” ì‹œí‚¤ê¸°
def user_info():
    all_user = Users.objects.values('user_id','degree_code', 'city_code', 'favorite', 'age','gender')
    
    # job ì½”ë“œ ë³€ìˆ˜
    js = JobSubFamily.objects.all()
    jc = JobCategory.objects.all()
    # ì§€ì—­ë³€ìˆ˜
    city = Cities.objects.all()
    region = Regions.objects.all()
    
    # ìœ ì €ê²½ë ¥ ë³€ìˆ˜
    career = Careers.objects.all()

    # ì§ì—… ì¤‘ë¶„ë¥˜ - í–‰ë ¬ ì¸ë±ìŠ¤ ë§¤ì¹­
    sub_to_index = {}
    for i in range(len(js)):
        sub_to_index[js[i].job_sub_code] = i+14

    # ì§€ì—­ - í–‰ë ¬ ì¸ë±ìŠ¤ ë§¤ì¹­
    city_to_region = {}
    city_to_index = {}
    region_to_index = {}

    i = 126
    for k in region:
        region_to_index[k.region_code] = i
        i += 1
    
    # city - region ë§¤ì¹­
    # city - í–‰ë ¬ ì¸ë±ìŠ¤ ë§¤ì¹­
    for j in range(len(city)):
        city_to_region[city[j].city_code] = city[j].region_code.region_code
        city_to_index[city[j].city_code] = j + 144


    #######################################################
    # í–‰ë ¬ë§Œë“¤ê¸°
    # ì „ì²´ ì—´ ê°œìˆ˜ 384ê°œ

    # ìš°ì„  ì „ì²´ ìœ ì €ì˜ ìˆ˜ êµ¬í•˜ê¸°
    user_length = all_user.aggregate(Max('user_id'))
    userMatrix = [[0]*384 for _ in range(user_length['user_id__max']+1)]

    # ê²½ë ¥ì— ëŒ€í•´ matrixì— ê¸°ë¡í•´ì£¼ê¸°
    # í•™ë ¥ - 373 4 5 6
    # ë‚˜ì´ - 378 9 380 381
    # ì„±ë³„ - 382 383
    for car in career:
        user_num = car.user_id
        job_num = car.sub_code.job_sub_code
        # 1ë…„ì€ +1
        if car.period == 1:
            userMatrix[user_num][sub_to_index[job_num]] += 1
        # 2,3ë…„ì€ +2
        elif car.period == 2 or car.period == 3:
            userMatrix[user_num][sub_to_index[job_num]] += 2
        # 4,5ë…€ëŠ” +3
        elif car.period == 4 or car.period == 5:
            userMatrix[user_num][sub_to_index[job_num]] += 3

    # ìœ ì € ì •ë³´ì— ëŒ€í•´ matrixì— ê¸°ë¡
    for us in all_user:
        # ì´ë ¥ì„œ ì‘ì„±í•œ ì‚¬ëŒì— í•œí•´ 
        if us['degree_code']:
            us_num = us['user_id']
            fav = us['favorite']
            us_city = us['city_code']
            deg = us['degree_code']
            us_age = us['age']
            us_gen = us['gender']
        else:
            continue

        # ìœ ì € ê´€ì‹¬ ì§ì¢… +3 í•´ì£¼ê¸°
        userMatrix[us_num][sub_to_index[fav]] += 3

        # ì§€ì—­ +1 í•´ì£¼ê¸°
        userMatrix[us_num][city_to_index[us_city]] += 1
        userMatrix[us_num][region_to_index[city_to_region[us_city]]] += 1

        # í•™ë ¥ ê¸°ë¡í•´ì£¼ê¸°
        if deg == 0:
            userMatrix[us_num][373:377] = [0,0,0,0]
        elif deg == 4:
            userMatrix[us_num][373:377] = [0,0,0,1]
        elif deg == 5:
            userMatrix[us_num][373:377] = [0,0,1,1]
        elif deg == 6:
            userMatrix[us_num][373:377] = [0,1,1,1]
        elif deg == 7:
            userMatrix[us_num][373:377] = [1,1,1,1]

        # ë‚˜ì´ ê¸°ë¡í•´ì£¼ê¸°
        if us_age < 55:        
            userMatrix[us_num][378] = 1
        elif 55 <= us_age < 60:
            userMatrix[us_num][379] = 1
        elif 60 <= us_age < 65:
            userMatrix[us_num][380] = 1
        elif 65 <= us_age:
            userMatrix[us_num][381] = 1


        # ì„±ë³„ - ë‚¨ 1 ì—¬ 2
        if us_gen == 0:
            userMatrix[us_num][382] = 1
        else:
            userMatrix[us_num][383] = 1

    # ìœ ì € ë§¤íŠ¸ë¦­ìŠ¤ë¡œ ì €ì¥
    # np.save('./data/userMatrix', userMatrix)

    # ìœ ì‚¬ë„ë¡œ ì €ì¥í•´ì£¼ê¸°
    calc_sim_user = cosine_similarity(userMatrix, userMatrix)
    sorted_index = np.argsort(calc_sim_user)[:, ::-1]
    sorted_index = sorted_index[:, 1:]
    return

def load_user_matrix(user_num):
    return 



# ìœ ì € -> ì±„ìš©ê³µê³ ì— í‰ì ë§¤ê¸°ê¸°
def user_to_job():
    ap_job = ApplyStatus.objects.all()
    cl_job = ClickWanted.objects.all()
    li_job = LikeWanted.objects.all()

    # ìš°ì„  ì „ì²´ ìœ ì €ì˜ ìˆ˜, ì „ì²´ ê³µê³ ì˜ ìˆ˜ êµ¬í•˜ê¸°
    # í–‰ë²ˆí˜¸ -> ìœ ì € ë²ˆí˜¸, ì—´ ë²ˆí˜¸ -> ê³µê³  ë²ˆí˜¸
    user_length = Users.objects.aggregate(Max('user_id'))
    job_length = Wanted.objects.aggregate(Max('wanted_code'))
    userMatrix = [[0]*(job_length['wanted_code__max']+1) for _ in range(user_length['user_id__max']+1)]

    # ë²¡í„°ì— ê°€ì¤‘ì¹˜ ì£¼ê¸° -> ì§€ì› 3ì , í´ë¦­ 1ì , ë¶ë§ˆí¬ 2ì 
    for a in ap_job:
        userMatrix[a.user_id][a.wanted_code.wanted_code] += 3
    
    for c in cl_job:
        userMatrix[c.user_id][c.wanted_code.wanted_code] += 1
    
    for l in li_job:
        userMatrix[l.user_id][l.wanted_code.wanted_code] += 2

    np.save('./data/user_to_job', userMatrix)
    return


# csr í–‰ë ¬ë¡œ ë³€í™˜í•´ì£¼ê¸°
def csr_matrix():
    mat = np.load('./data/user_to_job.npy')
    csr = sparse.csr_matrix(mat)
    # í–‰ë ¬ ì‚¬ì´ì¦ˆ
    matrix_size = csr.shape[0]* csr.shape[1]
    print(matrix_size)
    # ìœ íš¨í•œ ë°ì´í„°
    num_active = len(csr.nonzero()[0])
    print(num_active)
    # 0ì´ ë“¤ì–´ìˆëŠ” í¼ì„¼íŠ¸
    sparsity = 100 * (1-(num_active/matrix_size))
    print(sparsity)
    return



## í›ˆë ¨ ë°ì´í„° ë§Œë“¤ê¸°

def make_train(matrix, percentage = .2):

    '''
    ----------------------------------------------------
    ì„¤ëª…
    ìœ ì €-ì•„ì´í…œ í–‰ë ¬ (matrix)ì—ì„œ 
    1. 0 ì´ìƒì˜ ê°’ì„ ê°€ì§€ë©´ 1ì˜ ê°’ì„ ê°–ë„ë¡ binaryí•˜ê²Œ í…ŒìŠ¤íŠ¸ ë°ì´í„°ë¥¼ ë§Œë“¤ê³ 
    2. í›ˆë ¨ ë°ì´í„°ëŠ” ì›ë³¸ í–‰ë ¬ì—ì„œ percentage ë¹„ìœ¨ë§Œí¼ 0ìœ¼ë¡œ ë°”ë€œ
    
    -----------------------------------------------------
    ë°˜í™˜
    training_set: í›ˆë ¨ ë°ì´í„°ì—ì„œ percentage ë¹„ìœ¨ë§Œí¼ 0ìœ¼ë¡œ ë°”ë€ í–‰ë ¬
    test_set:     ì›ë³¸ ìœ ì €-ì•„ì´í…œ í–‰ë ¬ì˜ ë³µì‚¬ë³¸
    user_inds:    í›ˆë ¨ ë°ì´í„°ì—ì„œ 0ìœ¼ë¡œ ë°”ë€ ìœ ì €ì˜ index

    '''
    test_set = matrix.copy()
    test_set[test_set != 0] = 1 # binaryí•˜ê²Œ ë§Œë“¤ê¸°


    training_set = matrix.copy()
    nonzero_inds = training_set.nonzero()
    nonzero_pairs = list(zip(nonzero_inds[0], nonzero_inds[1]))

    random.seed(0)
    num_samples = int(np.ceil(percentage * len(nonzero_pairs)))
    samples = random.sample(nonzero_pairs, num_samples)

    user_inds = [index[0] for index in samples]
    item_inds = [index[1] for index in samples]

    training_set[user_inds, item_inds] = 0
    training_set.eliminate_zeros()

    return training_set, test_set, list(set(user_inds))


# í›ˆë ¨, í…ŒìŠ¤íŠ¸ ë°ì´í„° ìƒì„±
mat = np.load('./data/user_to_job.npy')
csr = sparse.csr_matrix(mat)
product_train, product_test, product_users_altered = make_train(csr, 0.2)


def implicit_weighted_ALS(training_set, lambda_val = .1, alpha = 40, n_iter=10, rank_size = 20, seed = 0):
    '''
    í˜‘ì—… í•„í„°ë§ì— ê¸°ë°˜í•œ ALS
    -----------------------------------------------------
    input
    1. training_set : m x n í–‰ë ¬ë¡œ, mì€ ìœ ì € ìˆ˜, nì€ ì•„ì´í…œ ìˆ˜ë¥¼ ì˜ë¯¸. csr í–‰ë ¬ (í¬ì†Œ í–‰ë ¬) í˜•íƒœì—¬ì•¼ í•¨ 
    2. lambda_val: ALSì˜ ì •ê·œí™” term. ì´ ê°’ì„ ëŠ˜ë¦¬ë©´ biasëŠ” ëŠ˜ì§€ë§Œ ë¶„ì‚°ì€ ê°ì†Œ. defaultê°’ì€ 0.1
    3. alpha: ì‹ ë¢° í–‰ë ¬ê³¼ ê´€ë ¨í•œ ëª¨ìˆ˜ (C_{ui} = 1 + alpha * r_{ui}). ì´ë¥¼ ê°ì†Œì‹œí‚¤ë©´ í‰ì  ê°„ì˜ ì‹ ë¢°ë„ì˜ ë‹¤ì–‘ì„±ì´ ê°ì†Œ
    4. n_iter: ë°˜ë³µ íšŸìˆ˜
    5. rank_size: ìœ ì €/ ì•„ì´í…œ íŠ¹ì„± ë²¡í„°ì˜ ì ì¬ íŠ¹ì„±ì˜ ê°œìˆ˜. ë…¼ë¬¸ì—ì„œëŠ” 20 ~ 200 ì‚¬ì´ë¥¼ ì¶”ì²œí•˜ê³  ìˆìŒ. ì´ë¥¼ ëŠ˜ë¦¬ë©´ ê³¼ì í•© ìœ„í—˜ì„±ì´ ìˆìœ¼ë‚˜ 
    biasê°€ ê°ì†Œ
    6. seed: ë‚œìˆ˜ ìƒì„±ì— í•„ìš”í•œ seed
    -----------------------------------------------------
    ë°˜í™˜
    ìœ ì €ì™€ ì•„ì´í…œì— ëŒ€í•œ íŠ¹ì„± ë²¡í„°
    '''
    start = time()
    # 1. Confidence matrix
    # C = 1+ alpha * r_{ui}
    conf = (alpha*training_set)  # sparse í–‰ë ¬ í˜•íƒœë¥¼ ìœ ì§€í•˜ê¸° ìœ„í•´ì„œ 1ì„ ë‚˜ì¤‘ì— ë”í•¨

    num_user = conf.shape[0]
    num_item = conf.shape[1]

    # Xì™€ Y ì´ˆê¸°í™”
    rstate = np.random.RandomState(seed)
    X = sparse.csr_matrix(rstate.normal(size = (num_user, rank_size)))
    Y = sparse.csr_matrix(rstate.normal(size = (num_item, rank_size)))
    X_eye = sparse.eye(num_user)
    Y_eye = sparse.eye(num_item)
    
    # ì •ê·œí™” term: ğ€I
    lambda_eye = lambda_val * sparse.eye (rank_size)
    
    # ë°˜ë³µ ì‹œì‘
    for i in range(n_iter):
        yTy = Y.T.dot(Y)
        xTx = X.T.dot(X)
        
        # Yë¥¼ ê³ ì •í•´ë†“ê³  Xì— ëŒ€í•´ ë°˜ë³µ
        # Xu = (yTy + yT(Cu-I)Y + ğ€I)^{-1} yTCuPu
        for u in range(num_user):
            conf_samp = conf[u,:].toarray() # Cu
            pref = conf_samp.copy()
            pref[pref!=0] = 1
            # Cu-I: ìœ„ì—ì„œ confì— 1ì„ ë”í•˜ì§€ ì•Šì•˜ìœ¼ë‹ˆê¹Œ Ië¥¼ ë¹¼ì§€ ì•ŠìŒ 
            CuI = sparse.diags(conf_samp, [0])
            # yT(Cu-I)Y
            yTCuIY = Y.T.dot(CuI).dot(Y)
            # yTCuPu
            yTCupu = Y.T.dot(CuI+Y_eye).dot(pref.T)
            
            X[u] = spsolve(yTy + yTCuIY + lambda_eye, yTCupu)
        
        # Xë¥¼ ê³ ì •í•´ë†“ê³  Yì— ëŒ€í•´ ë°˜ë³µ
        # Yi = (xTx + xT(Cu-I)X + ğ€I)^{-1} xTCiPi
        for i in range(num_item):
            conf_samp = conf[:,i].T.toarray()
            pref = conf_samp.copy()
            pref[pref!=0] = 1
            
            #Ci-I
            CiI = sparse.diags (conf_samp, [0])
            # xT(Ci-I)X
            xTCiIX = X.T.dot(CiI).dot(X)
            # xTCiPi
            xTCiPi = X.T.dot(CiI+ X_eye).dot(pref.T)
            
            Y[i] = spsolve(xTx + xTCiIX + lambda_eye, xTCiPi)
        end = time()
        print(end-start)
        return X, Y.T
    

user_vecs, item_vecs = implicit_weighted_ALS(product_train, lambda_val = 0.1, alpha = 15, n_iter= 1,rank_size = 20, seed=0)
